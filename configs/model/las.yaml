architecture: las
input_size: 80
encoder_hidden_size: 256
decoder_hidden_size: 512
encoder_layers: 3
decoder_layers: 2
dropout: 0.3
bidirectional: True
rnn_type: lstm
teacher_forcing_ratio: 1.0
use_joint_ctc_attention: False
max_len: 120
attn_mechanism: location
smoothing: False