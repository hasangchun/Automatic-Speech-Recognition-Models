architecture: las
input_size: 80
encoder_hidden_size: 256
decoder_hidden_size: 512
encoder_layers: 3
decoder_layers: 2
num_head: 8
dropout: 0.3
bidirectional: True
rnn_type: lstm
teacher_forcing_ratio: 1.0
use_joint_ctc_attention: False
max_len: 120
attn_mechanism: multi_head
smoothing: False